{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from python_speech_features import mfcc\n",
    "import scipy.io.wavfile as wav\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "def read_labeled_image_list(image_list_file):\n",
    "    \"\"\"Reads a .txt file containing pathes and labeles\n",
    "    Args:\n",
    "       image_list_file: a .txt file with one /path/to/image per line\n",
    "       label: optionally, if set label will be pasted after each line\n",
    "    Returns:\n",
    "       List with all filenames in file image_list_file\n",
    "    \"\"\"\n",
    "    f = open(image_list_file, 'r')\n",
    "    filenames = []\n",
    "    labels = []\n",
    "    for line in f:\n",
    "        filename, label = line[:-1].split(' ')\n",
    "        filenames.append(filename)\n",
    "        labels.append(int(label))\n",
    "    return filenames, labels\n",
    "\n",
    "\n",
    "X_Train = np.ones((1659,13,950,1)) # 166 * 9 165 * 1\n",
    "Y_Train = np.zeros((1659,2))\n",
    "\n",
    "X_Test = np.ones((166,13,950,1))\n",
    "Y_Test = np.zeros((166,2))\n",
    "\n",
    "file_list, label_list = read_labeled_image_list('trainlabel_mj.txt')\n",
    "\n",
    "\n",
    "def getMFCC(filename):\n",
    "    (rate,sig) = wav.read(filename)\n",
    "    sig = sig[0:int(9.51*rate)]\n",
    "    mfcc_feat = mfcc(sig,rate)\n",
    "#    preprocess_mfcc = mfcc_feat-(np.mean(mfcc_feat, axis=0) + 1e-8)\n",
    "\n",
    "#    fig, ax = plt.subplots()\n",
    "    mfcc_data = np.swapaxes(mfcc_feat, 0, 1) #mfcc_feat\n",
    "\n",
    "    return mfcc_data\n",
    "#    print(mfcc_data)\n",
    "#    cax = ax.imshow(mfcc_data, interpolation='nearest', cmap=cm.coolwarm, origin='lower',aspect='auto')\n",
    "#    ax.set_title('MFCC')\n",
    "\n",
    "\n",
    "#    plt.show()\n",
    "\n",
    "#    fig, ax = plt.subplots()\n",
    "#    mfcc_data2 = np.swapaxes(preprocess_mfcc, 0, 1)\n",
    "#    print(mfcc_data2)\n",
    "#    cax = ax.imshow(mfcc_data2, interpolation='nearest', cmap=cm.coolwarm, origin='lower',aspect='auto')\n",
    "#    ax.set_title('MFCC')\n",
    "\n",
    "#    plt.show()\n",
    "    \n",
    "def get_train(image_list, label_list, idx):\n",
    "\n",
    "    for i in range(64*(idx-1),64*idx) :\n",
    "        tempary = getMFCC(image_list[i])\n",
    "        temp_ = np.ones((13,950,1))\n",
    "        for r in range(13):\n",
    "            for c in range(950):\n",
    "                temp_[r][c][0] = tempary[r][c]\n",
    "        \n",
    "        X_Train[i-(64*(idx-1))] = temp_\n",
    "        Y_Train[i-(64*(idx-1))][label_list[i]] = 1\n",
    "    return (X_Train, Y_Train)\n",
    "\n",
    "def fill_train(image_list, label_list):\n",
    "    for i in range(0, 1659):\n",
    "        tempary = getMFCC(image_list[i])\n",
    "        temp_ = np.ones((13,950,1))\n",
    "        for r in range(13):\n",
    "            for c in range(950):\n",
    "                X_Train[i][r][c][0] = tempary[r][c]\n",
    "        Y_Train[i][label_list[i]]=1\n",
    "    \n",
    "    return (X_Train, Y_Train)\n",
    "        \n",
    "        \n",
    "def get_test(image_list, label_list, k):\n",
    "    for i in range(166*k, 166*(k+1)):\n",
    "        if(i==1659):\n",
    "            continue\n",
    "\n",
    "        tempary = getMFCC(image_list[i])\n",
    "        temp_ = np.ones((13,950,1))\n",
    "        for r in range(13):\n",
    "            for c in range(950):\n",
    "                temp_[r][c][0] = tempary[r][c]\n",
    "        \n",
    "        X_Test[i-(166*k)] = temp_\n",
    "        Y_Test[i-(166*k)][label_list[i]] = 1\n",
    "    return (X_Test, Y_Test)\n",
    "\n",
    "# (X_Test, Y_Test) = get_test(file_list, label_list)\n",
    "(X_Train, Y_Train) = fill_train(file_list, label_list)\n",
    "\n",
    "batch_x = np.ones((64,13,950,1))\n",
    "batch_y = np.zeros((64,2))\n",
    "\n",
    "def get_batch(i, k):\n",
    "    for idx in range(64*(i-1),64*i):\n",
    "        \n",
    "        if(idx>=166*k):\n",
    "            real_idx = idx+166\n",
    "        else:\n",
    "            real_idx = idx\n",
    "            \n",
    "        batch_x[idx-(64*(i-1))] = X_Train[real_idx]\n",
    "        batch_y[idx-(64*(i-1))] = Y_Train[real_idx]\n",
    "    return (batch_x, batch_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder('float', [None, 13, 950, 1])\n",
    "Y = tf.placeholder('float', [None, 2])\n",
    "keep_prob = tf.placeholder('float')\n",
    "\n",
    "W1 = tf.get_variable(\"W11\", shape=[2, 20, 1, 16],initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "#W1 = tf.Variable(tf.random_normal([2, 20, 1, 64], stddev = 0.01))\n",
    "L1 = tf.nn.conv2d(X, W1, strides=[1,1,1,1], padding='SAME')\n",
    "L1 = tf.maximum(0.2*L1, 0.01*L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1,1,10,1], strides=[1,1,5,1], padding='SAME')  #13*190*16\n",
    "\n",
    "print(\"L1.shape : \",L1.shape)\n",
    "\n",
    "\n",
    "W2 = tf.get_variable(\"W21\", shape=[2, 10, 16, 32],initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "#W2 = tf.Variable(tf.random_normal([2,10,64,64], stddev = 0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1,1,1,1], padding='SAME')\n",
    "L2 = tf.maximum(0.2*L2, 0.01*L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1,1,7,1], strides=[1,1,5,1], padding='SAME')   #13*38*32\n",
    "\n",
    "print(\"L2.shape : \",L2.shape)\n",
    "\n",
    "#W3 = tf.get_variable(\"W3\", shape=[2, 5, 64, 64],initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "##W3 = tf.Variable(tf.random_normal([2,5,64,64], stddev = 0.01))\n",
    "#L3 = tf.nn.conv2d(L2, W3, strides=[1,1,1,1], padding='SAME')\n",
    "#L3 = tf.maximum(0.3*L3, 0.05*L3)\n",
    "#L3 = tf.nn.max_pool(L3, ksize=[1,1,4,1], strides=[1,1,2,1], padding='SAME')   #13*10*64\n",
    "\n",
    "#print(\"L3.shape : \",L3.shape)\n",
    "11\n",
    "W4 = tf.get_variable(\"W41\", shape=[13*38*32, 1024],initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "#W4 = tf.Variable(tf.random_normal([7*10*64, 1024], stddev=0.01))\n",
    "L4 = tf.reshape(L2, [-1, 13*38*32])\n",
    "L4 = tf.matmul(L4, W4)\n",
    "L4 = tf.maximum(0.2*L4, 0.01*L4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob)\n",
    "\n",
    "W5 = tf.get_variable(\"W51\", shape=[1024, 256],initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "#W5 = tf.Variable(tf.random_normal([1024, 256], stddev=0.01))\n",
    "L5 = tf.matmul(L4, W5)\n",
    "L5 = tf.maximum(0.2*L5, 0.01*L5)\n",
    "L5 = tf.nn.dropout(L5, keep_prob)\n",
    "\n",
    "W6 = tf.get_variable(\"W61\", shape=[256, 2],initializer=tf.contrib.layers.variance_scaling_initializer())\n",
    "#W6 = tf.Variable(tf.random_normal([256, 2], stddev=0.01))\n",
    "model = tf.nn.softmax(tf.matmul(L5,W6))#tf.nn.softmax(tf.matmul(L5, W6))\n",
    "\n",
    "#W3 = tf.Variable(tf.random_normal([3,3,32,64], stddev = 0.01))\n",
    "#L3 = tf.nn.conv2d(L2, W3, strides=[1,1,1,1], padding='SAME')\n",
    "#L3 = tf.nn.relu(L3)\n",
    "#L3 = tf.nn.max_pool(L3, ksize=[1,3,3,1], strides=[1,2,2,1], padding='SAME')    #43*28*64\n",
    "\n",
    "#W4 = tf.Variable(tf.random_normal([3,3,64,64], stddev = 0.01))\n",
    "#L4 = tf.nn.conv2d(L3, W4, strides=[1,1,1,1], padding='SAME')\n",
    "#L4 = tf.nn.relu(L4)\n",
    "#L4 = tf.nn.max_pool(L4, ksize=[1,3,3,1], strides=[1,2,2,1], padding='SAME')     #22*14*64\n",
    "\n",
    "#W5 = tf.Variable(tf.random_normal([3,3,64,64], stddev = 0.01))\n",
    "#L5 = tf.nn.conv2d(L4, W5, strides=[1,1,1,1], padding='SAME')\n",
    "#L5 = tf.nn.relu(L5)\n",
    "#L5 = tf.nn.max_pool(L5, ksize=[1,3,3,1], strides=[1,2,2,1], padding='SAME')     #11*7*64\n",
    "\n",
    "\n",
    "#W6 = tf.Variable(tf.random_normal([7*11*64, 256], stddev=0.01))\n",
    "#L6 = tf.reshape(L5, [-1,7*11*64])\n",
    "#L6 = tf.matmul(L6, W6)\n",
    "#L6 = tf.nn.relu(L6)\n",
    "#L6 = tf.nn.dropout(L6, keep_prob)\n",
    "\n",
    "#W7 = tf.Variable(tf.random_normal([256,64], stddev=0.01))\n",
    "#L7 = tf.matmul(L6, W7)\n",
    "#L7 = tf.nn.relu(L7)\n",
    "\n",
    "\n",
    "#W8 = tf.Variable(tf.random_normal([64, 2], stddev=0.01))\n",
    "#model = tf.matmul(L7, W8)\n",
    "\n",
    "model_clipped = tf.clip_by_value(model, 1e-10, 0.9999999999)\n",
    "cross_entropy = -tf.reduce_mean(tf.reduce_sum(Y*tf.log(model_clipped)+(1-Y)*tf.log(1-model_clipped),axis=1))\n",
    "\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.000000037).minimize(cross_entropy)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 5\n",
    "total_batch = int(1494/64)\n",
    "is_correct = tf.equal(tf.argmax(Y,1), tf.argmax(model,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, 'float'))\n",
    "\n",
    "TP = tf.count_nonzero(tf.argmax(model,1) * tf.argmax(Y,1))\n",
    "TN = tf.count_nonzero((tf.argmax(model,1)-1) * (tf.argmax(Y,1)-1))\n",
    "FP = tf.count_nonzero(tf.argmax(model,1) * (tf.argmax(Y ,1)-1))\n",
    "FN = tf.count_nonzero((tf.argmax(model,1)-1) * tf.argmax(Y,1))\n",
    "\n",
    "for k in range(0, 10):\n",
    "    with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "        sess.run(init)\n",
    "        for epoch in range(2000):\n",
    "            total_cost = 0\n",
    "            for i in range(total_batch):\n",
    "                #(x_data, y_data) = get_train(file_list, label_list, i+1)\n",
    "                (x_data, y_data) = get_batch(i+1, k)\n",
    "                _, cost_val = sess.run([optimizer, cross_entropy], feed_dict={X:x_data, Y:y_data, keep_prob:0.7})\n",
    "                total_cost += cost_val / total_batch\n",
    "            if(epoch%100 == 0 or epoch%100 == 1):\n",
    "                (X_Test, Y_Test) = get_test(file_list, label_list, k)\n",
    "                print('Epoch: %04d' % (epoch+1),\n",
    "                     'Avg. cost = %.3f' % (total_cost))\n",
    "                print('accuracy: ',sess.run([accuracy,model,Y], feed_dict={X:X_Test, Y:Y_Test, keep_prob:1}))\n",
    "                print('TP: ',sess.run(TP,feed_dict={X:X_Test, Y:Y_Test, keep_prob:1}))\n",
    "                print('TN: ',sess.run(TN,feed_dict={X:X_Test, Y:Y_Test, keep_prob:1}))\n",
    "                print('FP: ',sess.run(FP,feed_dict={X:X_Test, Y:Y_Test, keep_prob:1}))\n",
    "                print('FN: ',sess.run(FN,feed_dict={X:X_Test, Y:Y_Test, keep_prob:1}))\n",
    "    \n",
    "        print('complete optimization')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        print('accuracy: ',sess.run([accuracy,model,Y], feed_dict={X:X_Test, Y:Y_Test, keep_prob:1}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
